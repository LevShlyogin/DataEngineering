{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1VM2FgVXaWlGZMhwqYRQuR7cnXd8FzP_2","authorship_tag":"ABX9TyOb8+KXlq1VSHnlUxHJeZwc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Первая задача"],"metadata":{"id":"ytSregKXlGdk"}},{"cell_type":"code","source":["import json\n","from bs4 import BeautifulSoup\n","import re\n","import numpy as np"],"metadata":{"id":"ETSWzaLltR-b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","import re\n","import json\n","import numpy as np\n","\n","\n","def parse_file(f_name):\n","    with open(f_name, encoding=\"utf-8\") as f:\n","        text = \"\"\n","        for line in f.readlines():\n","            text += line\n","\n","        site = BeautifulSoup(text, \"html.parser\")\n","\n","        item = dict()\n","        item[\"type\"] = site.find_all(\"span\", string=re.compile(\"Тип:\"))[0].get_text().replace(\"Тип:\", \"\").strip()\n","        item[\"title\"] = site.find_all(\"h1\")[0].get_text().replace(\"Турнир:\", \"\").strip()\n","\n","        address = site.find_all(\"p\", attrs={\"class\": \"address-p\"})[0].get_text().split(\"Начало:\")\n","        item[\"city\"] = address[0].split()[-1].strip()\n","        item[\"date_start\"] = address[1].strip()\n","\n","        item[\"count\"] = int(site.find_all(\"span\", attrs={\"class\": \"count\"})[0]\n","                            .get_text().split(\"Количество туров:\")[-1].strip())\n","        item[\"time_control\"] = site.find_all(\"span\", attrs={\"class\": \"year\"})[0] \\\n","            .get_text().split(\"Контроль времени:\")[-1].strip()\n","        item[\"min_rating\"] = int(site.find_all(\"span\", string=re.compile(\"Минимальный рейтинг для участия:\"))[0]\n","                                 .get_text().split(\"Минимальный рейтинг для участия:\")[-1].strip())\n","        item[\"img\"] = site.find_all(\"img\")[0][\"src\"]\n","        item[\"rating\"] = float(site.find_all(\"span\", string=re.compile(\"Рейтинг:\"))[0]\n","                               .get_text().split(\"Рейтинг:\")[-1].strip())\n","        item[\"views\"] = int(site.find_all(\"span\", string=re.compile(\"Просмотры:\"))[0]\n","                            .get_text().split(\"Просмотры:\")[-1].strip())\n","    return item\n","\n","\n","def calc_stats(col, items_lst):\n","    numbers = list(map(lambda x: x[col], items_lst))\n","    numeric_stats = {'sum': sum(numbers),\n","                     'avg': round(np.average(numbers), 2),\n","                     'min': min(numbers),\n","                     'max': max(numbers),\n","                     'std': round(np.std(numbers), 2),\n","                     }\n","\n","    return numeric_stats\n","\n","\n","def calc_frequency(col, items_lst):\n","    frequency = {}\n","\n","    for item in items_lst:\n","        frequency[item[col]] = frequency.get(item[col], 0) + 1\n","\n","    return frequency\n","\n","\n","items = []\n","for i in range(1, 1000):\n","    file_name = f\"/content/Данные/{i}.html\"\n","    result = parse_file(file_name)\n","    items.append(result)\n","\n","items = sorted(items, key=lambda x: x[\"views\"], reverse=True)\n","\n","with open(\"results/task1_all.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(items, ensure_ascii=False))\n","\n","filtered_items = []\n","for tour in items:\n","    if tour[\"min_rating\"] >= 2500:\n","        filtered_items.append(tour)\n","\n","with open(\"results/task1_filtered_min_rating_2500.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(filtered_items, ensure_ascii=False))\n","\n","views_stats = calc_stats(\"views\", items)\n","with open(\"results/task1_views_stats.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(views_stats, ensure_ascii=False))\n","\n","city_freq = calc_frequency(\"city\", items)\n","with open(\"results/task1_city_freq.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(city_freq, ensure_ascii=False))"],"metadata":{"id":"MP46LfqKI6Jp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Вторая задача"],"metadata":{"id":"lcjoUC_U-m33"}},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","import numpy as np\n","import json\n","\n","\n","def handle_file(file_name):\n","    items = list()\n","\n","    with open(file_name, encoding=\"utf-8\") as file:\n","        text = \"\"\n","        for row in file.readlines():\n","            text += row\n","\n","        site = BeautifulSoup(text, 'html.parser')\n","        products = site.find_all(\"div\", attrs={'class': 'product-item'})\n","\n","        for product in products:\n","            item = dict()\n","            item['id'] = product.a['data-id']\n","            item['link'] = product.find_all('a')[1]['href']\n","            item['img_url'] = product.find_all('img')[0]['src']\n","            item['title'] = product.find_all('span')[0].get_text().strip()\n","            item['price'] = int(product.price.get_text().replace(\"₽\", \"\").replace(\" \", \"\").strip())\n","            item['bonus'] = int(product.strong.get_text().replace(\"+ начислим \", \"\").replace(\" бонусов\", \"\").strip())\n","            props = product.ul.find_all(\"li\")\n","            for prop in props:\n","                item[prop['type']] = prop.get_text().strip()\n","\n","            items.append(item)\n","\n","        return items\n","\n","\n","def calc_stats(col, items_lst):\n","    numbers = list(map(lambda x: x[col], items_lst))\n","    numeric_stats = {'sum': sum(numbers),\n","                     'avg': round(np.average(numbers), 2),\n","                     'min': min(numbers),\n","                     'max': max(numbers),\n","                     'std': round(np.std(numbers), 2),\n","                     }\n","\n","    return numeric_stats\n","\n","\n","def calc_frequency(col, items_lst):\n","    frequency = {}\n","\n","    for item in items_lst:\n","        if col in item:\n","            frequency[item[col]] = frequency.get(item[col], 0) + 1\n","\n","    return frequency\n","\n","\n","items = []\n","for i in range(1, 29):\n","    file_name = f\"tasks/task_2_var_54/{i}.html\"\n","    items += handle_file(file_name)\n","\n","items = sorted(items, key=lambda x: x['price'], reverse=True)\n","\n","with open(\"results/task2_all.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(items, ensure_ascii=False))\n","\n","filtered_items = []\n","for item in items:\n","    if item['bonus'] >= 2000:\n","        filtered_items.append(item)\n","\n","with open(\"results/task2_filtered_min_bonus_2000.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(filtered_items, ensure_ascii=False))\n","\n","price_stats = calc_stats(\"price\", items)\n","with open(\"results/task2_price_stats.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(price_stats, ensure_ascii=False))\n","\n","ram_freq = calc_frequency(\"ram\", items)\n","with open(\"results/task2_ram_freq.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(ram_freq, ensure_ascii=False))"],"metadata":{"id":"_n6FWapy-wN4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Третья задача"],"metadata":{"id":"pH8uIqAH_K5q"}},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","import numpy as np\n","import json\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","def handle_file(file_name):\n","    with open(file_name, encoding=\"utf-8\") as file:\n","        text = \"\"\n","        for row in file.readlines():\n","            text += row\n","\n","    star = BeautifulSoup(text, 'lxml').star\n","    item = dict()\n","    item[\"name\"] = star.find_all(\"name\")[0].get_text().strip()\n","    item[\"constellation\"] = star.find_all(\"constellation\")[0].get_text().strip()\n","    item[\"spectral-class\"] = star.find_all(\"spectral-class\")[0].get_text().strip()\n","    item[\"radius\"] = int(star.find_all(\"radius\")[0].get_text().strip())\n","    item[\"rotation\"] = star.find_all(\"rotation\")[0].get_text().strip()\n","    item[\"age\"] = star.find_all(\"age\")[0].get_text().strip()\n","    item[\"distance\"] = star.find_all(\"distance\")[0].get_text().strip()\n","    item[\"absolute-magnitude\"] = star.find_all(\"absolute-magnitude\")[0].get_text().strip()\n","\n","    return item\n","\n","\n","def calc_stats(col, items_lst):\n","    numbers = list(map(lambda x: x[col], items_lst))\n","    numeric_stats = {'sum': sum(numbers),\n","                     'avg': round(np.average(numbers), 2),\n","                     'min': min(numbers),\n","                     'max': max(numbers),\n","                     'std': round(np.std(numbers), 2),\n","                     }\n","\n","    return numeric_stats\n","\n","\n","def calc_frequency(col, items_lst):\n","    frequency = {}\n","\n","    for item in items_lst:\n","        if col in item:\n","            frequency[item[col]] = frequency.get(item[col], 0) + 1\n","\n","    return frequency\n","\n","items = []\n","for i in range(1, 501):\n","    file_name = f\"tasks/task_3_var_54/{i}.xml\"\n","    items.append(handle_file(file_name))\n","\n","items = sorted(items, key=lambda x: int(x['radius']), reverse=True)\n","\n","with open(\"results/task3_all.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(items, ensure_ascii=False))\n","\n","filtered_items = []\n","for item in items:\n","    if item['radius'] >= 900000000:\n","        filtered_items.append(item)\n","\n","with open(\"results/task3_filtered_min_radius_9e8.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(filtered_items, ensure_ascii=False))\n","\n","radius_stats = calc_stats(\"radius\", items)\n","with open(\"results/task3_radius_stats.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(radius_stats, ensure_ascii=False))\n","\n","constellation_freq = calc_frequency(\"constellation\", items)\n","with open(\"results/task3_constellation_freq.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(constellation_freq, ensure_ascii=False))"],"metadata":{"id":"iJq4v5Jx_jRf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Четвёртая задача"],"metadata":{"id":"ctIP8UzQ_URr"}},{"cell_type":"code","source":["import json\n","from bs4 import BeautifulSoup\n","import numpy as np\n","\n","\n","def handle_file(file_name):\n","    items = list()\n","\n","    with open(file_name, encoding=\"utf-8\") as file:\n","        text = \"\"\n","        for row in file.readlines():\n","            text += row\n","\n","        root = BeautifulSoup(text, 'xml')\n","\n","        for clothing in root.find_all(\"clothing\"):\n","            item = dict()\n","            for el in clothing.contents:\n","                if el.name is None:\n","                    continue\n","                elif el.name == \"price\" or el.name == \"reviews\":\n","                    item[el.name] = int(el.get_text().strip())\n","                elif el.name == \"rating\":\n","                    item[el.name] = float(el.get_text().strip())\n","                elif el.name == \"new\":\n","                    item[el.name] = el.get_text().strip() == \"+\"\n","                elif el.name == \"exclusive\" or el.name == \"sporty\":\n","                    item[el.name] = el.get_text().strip() == \"yes\"\n","                else:\n","                    item[el.name] = el.get_text().strip()\n","\n","            items.append(item)\n","\n","        return items\n","\n","\n","def calc_stats(col, items_lst):\n","    numbers = list(map(lambda x: x[col], items_lst))\n","    numeric_stats = {'sum': sum(numbers),\n","                     'avg': round(np.average(numbers), 2),\n","                     'min': min(numbers),\n","                     'max': max(numbers),\n","                     'std': round(np.std(numbers), 2),\n","                     }\n","\n","    return numeric_stats\n","\n","\n","def calc_frequency(col, items_lst):\n","    frequency = {}\n","\n","    for item in items_lst:\n","        if col in item:\n","            frequency[item[col]] = frequency.get(item[col], 0) + 1\n","\n","    return frequency\n","\n","\n","items = []\n","for i in range(1, 101):\n","    file_name = f\"tasks/task_4_var_54/{i}.xml\"\n","    items += handle_file(file_name)\n","\n","items = sorted(items, key=lambda x: x['price'], reverse=True)\n","\n","with open(\"results/task4_all.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(items, ensure_ascii=False))\n","\n","filtered_items = []\n","for item in items:\n","    if item['rating'] >= 4:\n","        filtered_items.append(item)\n","\n","with open(\"results/task4_filtered_min_rating_4.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(filtered_items, ensure_ascii=False))\n","\n","price_stats = calc_stats(\"price\", items)\n","with open(\"results/task4_price_stats.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(price_stats, ensure_ascii=False))\n","\n","category_freq = calc_frequency(\"category\", items)\n","with open(\"results/task4_category_freq.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(json.dumps(category_freq, ensure_ascii=False))"],"metadata":{"id":"lRtLFP3P_4W2"},"execution_count":null,"outputs":[]}]}